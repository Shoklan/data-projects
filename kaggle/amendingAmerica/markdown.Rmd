---
title: "Year With Most Proposed Amendements"
author: "Collin Mitchell"
date: "June 25, 2017"
output: html_document
---
Warming up for today, so I figured I'd play around with this dataset.

```{r include=TRUE, message=FALSE}
##> Libraries <##
library( rio )
library( dplyr )
library( purrr )
library( data.table )
library( ggplot2 )
library( knitr )
```

We're going to need a few basic packages - which I'll go over as I come to them.
First we're going to use the rio package to manage collecting the data from the flat file. This package is nice because it's an interface to many other packages that handle multiple formats.
```{r include=TRUE, echo=FALSE, warning=FALSE}
dataPath <- file.path( "data", "us-nara-amending-america-dataset-raw-2016-02-25.csv")
data<- import( dataPath )
```

Before working on the actual data, I want to make sure that the codepage given was correct and that it matches the actual data downloaded.

```{r, echo=TRUE}
# make sure codepage and data match
colnames( data )
```
Everything looks good so we're safe to move on.
Now, I've decided that I'll do a simple histogram of all the amendments by year. Looking over the data itself, there are quite a few columns I'm simply not going to use.
I'll leave some of the extra one for more interesting analysis later - if I decide to keep working on it.

```r
# Columns I don't care about:
# identifier
# source_code
# source_citation
# source_index_number
# congressional_session
# joint_resolution_chamber
# joint_resolution_number
# committee_of_referral
# last_modified

# rename:
  # state<- sponsor_state_or_territory
  # individual<- sponsor_name
  # approx<- date_approximation
  # purpose <- title_or_description_from_source

# Used this to check which columns contain data I think I'll use.
map(data, unique )
```

I'd rather work with the data in the data.table format since it's fast and flexible for most uses.
```{r include=TRUE}
# convert to data.table for quick conversion
data <- as.data.table( data )
```

This is where most of the real work is done - as cleaning really does take up most of the time.
First, I find the naming of the columns distasteful so I'll want to alter them for better readability.
Second, I'll pull out the columns I'm convinced I'll be using later.
Then, I'll need to correct the columns which should have been read in as numbers, but instead were treated as characters.
Finally, any values that are missing will be ignored. When I was exploring it before, there were - I believe - three values that were missing. This wont do too much damage to the results since we're doing a simple frequency count.

```{r include=TRUE}
# clean data
dataSlice <- 
  data %>%
  rename( state = sponsor_state_or_territory, individual = sponsor_name,                 # correct column names
          approx = date_approximation, purpose = title_or_description_from_source) %>%
  select( state, individual, approx, purpose, year, month, day, congress ) %>%           # only keep there columns
  mutate(year = as.numeric( year ),                                                      # convert to numbers
         month = as.numeric( month ),
         day = as.numeric( day ),
         congress = as.numeric( congress )) %>%
  filter( !is.na( year ))
```
Check to make sure the conversions were not botched

```{r include=TRUE}
# ensure that types were changed correctly
map( dataSlice, typeof )
```
When I plotted the data, I noticed there is a value mistyped. We certainly have not reached the year 19931 yet; that's a bit far away still. That's a simple mistake and can be corrected with a quick update.
```{r include=TRUE, echo=TRUE}
# there is a typo in the data; max year is 19931
summary( dataSlice )

# correct this.
index<- which( dataSlice$year == 19931 )
dataSlice$year[ index ] <- 1931
```
Now we're going to want to start graphing the results.
```{r include=TRUE, echo=TRUE}
# prepare graph
ggplot( dataSlice, aes( year )) + geom_histogram(bins = 23 )
# needs work
```
This graph works, but the data doesn't stand out very well. Lets fix this.
I'm going to use the cut function to create breaks in the data to make the differences more distinct - or, so it doesn't look like a grey blob.
To do that, I will need to to decide were to best make the cuts. Ten years should be intuitive enough to make the diffferences obvious given the span of time.

```{r include=TRUE}
# create cut factors
extremes<- range( dataSlice$year, na.rm = TRUE )
cutValues<- c( seq( extremes[1], extremes[2], by = 10), extremes[2])
```

After some trial and error, I noticed that the labels at the bottom of the graph were using the interval factors for the x axis labels. This made actually interpreting the graph impossible.
But, when I tried to simply use the cut values from before there was a different number of values between them. It appears that when making the cut, it is dropping the last value from the sequence.
So, I'll need to write a function that finds the mean between each cut section.

After considering the problem, I wrote the code below
```{r include=TRUE}
labels<- c( unlist(map( .x = 1:length( cutValues )-1, .f = function(x){
  mean( cutValues[x], cutValues[x+1])
}))[-1])
```
This code iterates over each index of the cutValeus Vector, and takes the mean of the this value and the next value.
Strangely, the first value comes out as NaN so I had to drop it; not really sure why but I don't need it anyways.

Now, update the year column with the new information and draw the plot!
```{r echo=TRUE,fig.width = 12, fig.height = 10, warning=FALSE}
# insert factors for graphing.
dataSlice$year<- cut(dataSlice$year, breaks = cutValues, labels = labels, ordered_result = TRUE)
ggplot( dataSlice, aes( year, fill = year )) + geom_histogram( stat =  "count")
```
I could work on cleaning up the y axis labels and the title along with the colors, but I think this is enough for now.

